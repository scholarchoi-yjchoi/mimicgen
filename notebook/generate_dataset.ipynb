{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e2ff454-b14a-4ef1-986c-9087c003ea53",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Imitation learning is a type of machine learning where an agent learns to imitate the actions of an expert. In order to train a robust agent, we need a large amount of data. However, manual data collection through human demonstrations is time-consuming and expensive.\n",
    "\n",
    "Isaac Lab Mimic is a feature included in Isaac Lab that allows users to generate new demonstrations by synthesizing trajectories using a small number of human demonstrations. This blueprint will show how to use Isaac Lab Mimic to generate new motion trajectories for a Franka robotic arm and then visually augment using NVIDIA Cosmos to create datasets for imitation learning. The workflow is broken down into two main steps:\n",
    "\n",
    "1. Generate new demonstrations by synthesizing trajectories using a small number of human demonstrations with Isaac Lab Mimic.\n",
    "2. Apply diverse visual transformations using NVIDIA Cosmos to the new demonstrations to create a large and diverse dataset.\n",
    "\n",
    "This notebook will guide you through each step of the workflow.\n",
    "\n",
    "**NOTE: This notebook must be run on the same machine as the Isaac Sim simulator and a display must be connected to the machine.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5741a94",
   "metadata": {},
   "source": [
    "# Understanding the Blueprint\n",
    "\n",
    "## Motion Trajectory Synthesis\n",
    "Isaac Lab Mimic is a feature set bundled with Isaac Lab (an open source robotic learning framework designed to help train robot policies). The core idea of Mimic is to allow users to synthetically generate a large number of new robot motion trajectories using only a handful of human demonstrations, thus greatly reducing the amount of time and effort required to collect a dataset for imitation learning. \n",
    "\n",
    "Human datasets are annotated with subtask information, which Isaac Lab Mimic uses to construct trajectories for new scene configurations by spatially transforming the original demonstrations.\n",
    "\n",
    "## Visual Augmentation\n",
    "Once generated, the new motion trajectories can be visually augmented using NVIDIA Cosmos to create a diverse dataset that is suitable for training an imitation learning policy. \n",
    "\n",
    "By using multi-staged data generation scheme, we can automatically create a robust dataset for training complex imitation learning policies without the need for large amounts of manual human data, greatly increasing the amount of data available for training and lowering the amount of time required to collect a dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7239a3",
   "metadata": {},
   "source": [
    "# Generate a New Motion Trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f4eee1",
   "metadata": {},
   "source": [
    "\n",
    "## Setup Initial Configuration for Isaac Lab\n",
    "\n",
    "This cell sets up the basic configuration for data generation:\n",
    "\n",
    "1. **How to Modify**:\n",
    "   - Adjust `num_envs` based on your GPU capability\n",
    "   - Set `generation_num_trials` to how many successful trials to execute. Note that some trials may be unsuccessful and so the total number of trials performed may be larger.\n",
    "\n",
    "2. **Tips**:\n",
    "   - Start with 1 trial for testing, increase for training. Increasing trails will increase the time it takes to generate the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d91d6e",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# [TIMING] Notebook Execution Timer - START\n# ============================================================\nimport time\nfrom datetime import datetime\n\nNOTEBOOK_START_TIME = time.time()\nNOTEBOOK_START_DATETIME = datetime.now()\nTIMING_LOG = {}  # ê° ë‹¨ê³„ë³„ ì‹œê°„ ê¸°ë¡\n\nprint(\"=\" * 60)\nprint(f\"[NOTEBOOK START] {NOTEBOOK_START_DATETIME.strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(\"=\" * 60)\n\n# ============================================================\n# Setup Initial Configuration\n# ============================================================\nfrom notebook_widgets import create_num_trials_input\n\nnum_envs = 1\nnum_trials = create_num_trials_input()"
  },
  {
   "cell_type": "markdown",
   "id": "ddc54d6a",
   "metadata": {},
   "source": [
    "## Spin up the Simulation\n",
    "\n",
    "Run this cell to start the simulation environment. This sets up the necessary components for data generation.\n",
    "\n",
    "**NOTE**: When the simulation is running, a **\"Isaac Sim\" is not responding.\"** pop up may appear. This is expected. Please click the **Wait** option and wait while the process completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2cf0f-cf3c-4383-a233-216ff1f48c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ì„ íƒ] ì´ ì…€ì€ Interactive Parameter Updatesë¥¼ ì‚¬ìš©í•  ë•Œë§Œ ì‹¤í–‰\n",
    "# Data Generationë§Œ í•„ìš”í•˜ë©´ ì´ ì…€ì„ ê±´ë„ˆë›°ì„¸ìš” (ë‹¤ìŒ ì…€ë¡œ ì´ë™)\n",
    "# ============================================================\n",
    "SKIP_SIMULATION = True  # Falseë¡œ ë³€ê²½í•˜ë©´ Simulation ì‹¤í–‰\n",
    "\n",
    "if SKIP_SIMULATION:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"âš ï¸  Simulation ì…€ ìŠ¤í‚µë¨ (SKIP_SIMULATION = True)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸ’¡ Data Generation ì…€ë¡œ ì´ë™í•˜ì„¸ìš”\")\n",
    "    print(\"   (Interactive Parameter Updatesë„ ìŠ¤í‚µ)\")\n",
    "    print(\"\")\n",
    "    print(\"ğŸ“Œ Interactive Parametersë¥¼ ì‚¬ìš©í•˜ë ¤ë©´:\")\n",
    "    print(\"   1. ìœ„ì—ì„œ SKIP_SIMULATION = False ë¡œ ë³€ê²½\")\n",
    "    print(\"   2. Kernel -> Restart í›„ ë‹¤ì‹œ ì‹¤í–‰\")\n",
    "else:\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # (260130) Added by yjchoi\n",
    "\n",
    "    # [Blackwell GPU í˜¸í™˜ì„± íŒ¨ì¹˜ - ìµœì¢…ì˜ ìµœì¢…]\n",
    "    import sys\n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    # 1. [ê²½ë¡œ ì„ ì ] ìš°ë¦¬ê°€ ì„¤ì¹˜í•œ 'pip_overrides'ë¥¼ ìµœìš°ì„  ìˆœìœ„ë¡œ ë“±ë¡\n",
    "    POD = \"/workspace/isaaclab/pip_overrides\"\n",
    "    if POD not in sys.path:\n",
    "        sys.path.insert(0, POD)\n",
    "\n",
    "    # 2. [ê°•ë ¥ ì°¨ë‹¨] Isaac Simì´ ëª°ë˜ ì‹¬ì–´ë†“ì€ êµ¬ë²„ì „(pip_prebundle) ê²½ë¡œ ì œê±°\n",
    "    sys.path = [p for p in sys.path if \"pip_prebundle\" not in p]\n",
    "\n",
    "    # 3. [í™˜ê²½ ë³€ìˆ˜ ì£¼ì…] ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ê°•ì œ ì„¤ì •\n",
    "    os.environ[\"PYTHONPATH\"] = POD + \":\" + os.environ.get(\"PYTHONPATH\", \"\")\n",
    "    libs = glob.glob(f\"{POD}/nvidia/*/lib\")\n",
    "    libs.append(f\"{POD}/torch/lib\")\n",
    "    os.environ[\"LD_LIBRARY_PATH\"] = \":\".join(libs) + \":\" + os.environ.get(\"LD_LIBRARY_PATH\", \"\")\n",
    "\n",
    "    print(\"ğŸš€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ì„¤ì • ì™„ë£Œ. ì¤‘ìš” ëª¨ë“ˆ ì„ ì  ë¡œë”© ì‹œì‘...\")\n",
    "\n",
    "    # 4. [ëª¨ë“ˆ ë°•ì œ] AppLauncherê°€ ì‹¤í–‰ë˜ê¸° ì „ì— ì˜¬ë°”ë¥¸ ë²„ì „ë“¤ì„ ë¯¸ë¦¬ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "    import torch\n",
    "    import torchvision  # <--- ì´ ì¹œêµ¬ê°€ ë‹¤ì‹œ ë“¤ì–´ê°”ìŠµë‹ˆë‹¤! (í•„ìˆ˜)\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "\n",
    "    # 5. [ê²€ì¦] ëˆˆìœ¼ë¡œ í™•ì¸\n",
    "    print(f\"âœ… Loaded Torch Ver: {torch.__version__}\")\n",
    "    print(f\"âœ… Loaded Vision Ver: {torchvision.__version__}\")\n",
    "    print(f\"âœ… Loaded Numpy Ver: {np.__version__}\")  # 1.26.4 ì—¬ì•¼ í•¨\n",
    "    print(f\"âœ… Loaded Scipy Ver: {scipy.__version__}\") # 1.12.0 ì—¬ì•¼ í•¨\n",
    "\n",
    "    # Visionì´ ìš°ë¦¬ í´ë”ì—ì„œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "    if \"pip_overrides\" in torchvision.__file__:\n",
    "        print(\"ğŸ‰ ì„±ê³µ! ì˜¬ë°”ë¥¸ Torchvisionì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(f\"ğŸ”¥ ê²½ê³ ! Torchvisionì´ ì—‰ëš±í•œ ê³³ì—ì„œ ë¡œë“œë¨: {torchvision.__file__}\")\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    import os\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    from argparse import ArgumentParser, Namespace\n",
    "    from isaaclab.app import AppLauncher\n",
    "\n",
    "    parser = ArgumentParser()\n",
    "    AppLauncher.add_app_launcher_args(parser)\n",
    "    args_cli = parser.parse_args([])\n",
    "    args_cli.enable_cameras = True\n",
    "    args_cli.kit_args = \"--enable omni.videoencoding\"\n",
    "\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    # (260202) Added by yjchoi\n",
    "\n",
    "    # [ìˆ˜ì • ì „]\n",
    "    # args_cli.headless = False \n",
    "\n",
    "    # [ìˆ˜ì • í›„: í™”ë©´ ì—†ì´ ê³„ì‚°ë§Œ í•˜ê² ë‹¤]\n",
    "    args_cli.headless = True\n",
    "    #-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    config = {\n",
    "        \"task\": \"Isaac-Stack-Cube-Franka-IK-Rel-Blueprint-Mimic-v0\",  \n",
    "        \"num_envs\": num_envs,                                       \n",
    "        \"generation_num_trials\": num_trials.value,                         \n",
    "        \"input_file\": \"datasets/annotated_dataset.hdf5\",     \n",
    "        \"output_file\": \"datasets/generated_dataset.hdf5\", \n",
    "        \"pause_subtask\": False,\n",
    "        \"enable\": \"omni.kit.renderer.capture\",\n",
    "    }\n",
    "\n",
    "    # Update the default configuration\n",
    "    args_dict = vars(args_cli)\n",
    "    args_dict.update(config)\n",
    "    args_cli = Namespace(**args_dict)\n",
    "\n",
    "    # Now launch the simulator with the final configuration\n",
    "    app_launcher = AppLauncher(args_cli)\n",
    "    simulation_app = app_launcher.app\n",
    "\n",
    "    import asyncio\n",
    "    import gymnasium as gym\n",
    "    import numpy as np\n",
    "    import random\n",
    "    import torch\n",
    "\n",
    "    import isaaclab_mimic.envs  # noqa: F401\n",
    "    from isaaclab_mimic.datagen.generation import env_loop, setup_env_config, setup_async_generation\n",
    "    from isaaclab_mimic.datagen.utils import get_env_name_from_dataset, setup_output_paths, interactive_update_randomizable_params, reset_env\n",
    "    from isaaclab.managers import ObservationTermCfg as ObsTerm\n",
    "    from notebook_utils import ISAACLAB_OUTPUT_DIR\n",
    "\n",
    "    import isaaclab_tasks  # noqa: F401\n",
    "    num_envs = args_cli.num_envs\n",
    "\n",
    "    # Setup output paths and get env name\n",
    "    output_dir, output_file_name = setup_output_paths(args_cli.output_file)\n",
    "    env_name = args_cli.task or get_env_name_from_dataset(args_cli.input_file)\n",
    "\n",
    "    # Configure environment\n",
    "    env_cfg, success_term = setup_env_config(\n",
    "        env_name=env_name,\n",
    "        output_dir=output_dir,\n",
    "        output_file_name=output_file_name,\n",
    "        num_envs=num_envs,\n",
    "        device=args_cli.device,\n",
    "        generation_num_trials=args_cli.generation_num_trials,\n",
    "    )\n",
    "    # Set observation output directory\n",
    "    for obs in vars(env_cfg.observations.rgb_camera).values():\n",
    "        if not isinstance(obs, ObsTerm):\n",
    "            continue\n",
    "        obs.params[\"image_path\"] = os.path.join(ISAACLAB_OUTPUT_DIR, obs.params[\"image_path\"])\n",
    "    env_cfg.observations\n",
    "\n",
    "\n",
    "    # create environment\n",
    "    env = gym.make(env_name, cfg=env_cfg).unwrapped\n",
    "\n",
    "    # set seed for generation\n",
    "    random.seed(env.cfg.datagen_config.seed)\n",
    "    np.random.seed(env.cfg.datagen_config.seed)\n",
    "    torch.manual_seed(env.cfg.datagen_config.seed)\n",
    "\n",
    "    # reset before starting\n",
    "    reset_env(env, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fd57b1",
   "metadata": {},
   "source": [
    "## Interactive Parameter Updates\n",
    "\n",
    "To get diversity in the generated motion trajectories, the scene configuration is randomized for each trial. This section provides interactive sliders and controls to adjust various environment parameters in real-time:\n",
    "\n",
    "1. **What You'll See**:\n",
    "   - Sliders for numerical values\n",
    "   - Range inputs for min/max settings\n",
    "   - Current value displays\n",
    "   - Parameter names and allowed ranges\n",
    "\n",
    "2. **How to Use**:\n",
    "   - Move the sliders to adjust values\n",
    "   - Watch the environment update in real-time\n",
    "\n",
    "3. **Available Parameters**:\n",
    "   - **Franka Joint State Randomization**:\n",
    "     - **mean (0.0 - 0.5)**: Controls the average joint angle offset (in radians)\n",
    "     - **std (0.0 - 0.1)**: Controls the spread of randomization around the mean\n",
    "\n",
    "   - **Cube Position Randomization**:\n",
    "     - **pose_range.x (0.3 - 0.9)**: Controls cube placement along the x-axis (in meters)\n",
    "     - **pose_range.y (-0.3 - 0.3)**: Controls cube placement along the y-axis (in meters)\n",
    "     - **min_separation (0.0 - 0.5)**: Minimum allowed distance between cubes (in meters)\n",
    "     \n",
    "     **Note:** If the system cannot place cubes with the specified minimum separation after several attempts (due to space constraints), it will accept the last generated positions even if they don't meet the separation requirement. This prevents the system from getting stuck in an impossible configuration.\n",
    "\n",
    "\n",
    "4. **Tips**:\n",
    "   - Start with small adjustments to understand their effects\n",
    "\n",
    "Note: These adjustments will affect how new demonstrations are generated, so take time to experiment with different settings to achieve desired behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec27b67f-d051-45e5-878f-2f6e1e6822f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# [ì„ íƒ] ì´ ì…€ì€ Interactive Parameter Updatesë¥¼ ì‚¬ìš©í•  ë•Œë§Œ ì‹¤í–‰\n",
    "# Data Generationë§Œ í•„ìš”í•˜ë©´ ì´ ì…€ì„ ê±´ë„ˆë›°ì„¸ìš” (ë‹¤ìŒ ì…€ë¡œ ì´ë™)\n",
    "# ============================================================\n",
    "SKIP_SIMULATION = True  # Falseë¡œ ë³€ê²½í•˜ë©´ Simulation ì‹¤í–‰\n",
    "\n",
    "if not SKIP_SIMULATION:\n",
    "    randomizable_params = {\n",
    "        \"randomize_franka_joint_state\": {\n",
    "            \"mean\": (0.0, 0.5, 0.01),\n",
    "            \"std\": (0.0, 0.1, 0.01),\n",
    "        },\n",
    "        \"randomize_cube_positions\": {\n",
    "            \"pose_range\": {\n",
    "                    \"x\": (0.3, 0.9, 0.01),\n",
    "                    \"y\": (-0.3, 0.3, 0.01),\n",
    "                },\n",
    "            \"min_separation\": (0.0, 0.5, 0.01),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    for i in range(len(env.unwrapped.event_manager._mode_term_cfgs[\"reset\"])):\n",
    "        event_term = env.unwrapped.event_manager._mode_term_cfgs[\"reset\"][i]\n",
    "        name = env.unwrapped.event_manager.active_terms[\"reset\"][i]\n",
    "        display(f\"Updating parameters for event: {event_term.func.__name__}\")\n",
    "        interactive_update_randomizable_params(event_term, name, randomizable_params[name], env=env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d35f42",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "Run this cell to start generating demonstrations using the parameters you've configured. The process will:\n",
    "- Generate the specified number of demonstrations\n",
    "- Save successful demonstrations to your output file\n",
    "- Show progress as demonstrations are generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035cd632-b2a5-4e23-8ad4-3df7e32a2512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": "# ============================================================\n# v17: Standalone ì „ìš© Data Generation (3ê°€ì§€ ê°œì„ )\n# - NUM_TRIALS í™˜ê²½ ë³€ìˆ˜ ëª…ë ¹ì–´ì— ì§ì ‘ ì „ë‹¬\n# - pip_overrides ë””ë ‰í† ë¦¬ì— íŒ¨í‚¤ì§€ ì„¤ì¹˜\n# ============================================================\nimport os\nimport sys\n\n# [TIMING] ì‹œì‘\n_data_gen_start = time.time()\n\nprint(\"=\" * 60)\nprint(\"[v17] Data Generation - Standalone ì „ìš©\")\nprint(\"=\" * 60)\n\n# í™˜ê²½ ë³€ìˆ˜ ê°’ ì¤€ë¹„\n#trials = num_trials.value\ntrials = 3\n\nprint(f\"[ì„¤ì •] ëª©í‘œ ìƒì„± íšŸìˆ˜: {trials}\")\nprint(\"-\" * 60)\n\n# í•„ìˆ˜ íŒ¨í‚¤ì§€ë¥¼ pip_overrides ë””ë ‰í† ë¦¬ì— ì„¤ì¹˜\nprint(\"[1/2] í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘ (pip_overrides)...\")\nsys.stdout.flush()\ninstall_code = os.system(\n    \"/isaac-sim/kit/python/bin/python3 -m pip install \"\n    \"--target=/workspace/isaaclab/pip_overrides \"\n    \"nest_asyncio toml -q\"\n)\nif install_code != 0:\n    print(f\"[WARNING] íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤íŒ¨ (ì½”ë“œ: {install_code}), ê³„ì† ì§„í–‰...\")\n\nprint(\"[2/2] standalone ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘...\")\nprint(\"(ì¶œë ¥ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤)\")\nprint(\"-\" * 60)\nsys.stdout.flush()\n\n# í™˜ê²½ ë³€ìˆ˜ë¥¼ ëª…ë ¹ì–´ì— ì§ì ‘ ì „ë‹¬\nreturn_code = os.system(\n    f\"cd /workspace/isaaclab && NUM_TRIALS={trials} \"\n    f\"./_isaac_sim/python.sh -u generate_data_standalone.py\"\n)\n\nif return_code != 0:\n    print(f\"\\n[ERROR] ì¢…ë£Œ ì½”ë“œ: {return_code}\")\nelse:\n    print(\"\\n[SUCCESS] ë°ì´í„° ìƒì„± ì™„ë£Œ!\")\n\n# [TIMING] ì¢…ë£Œ\nTIMING_LOG['data_generation'] = time.time() - _data_gen_start\nprint(f\"\\n[TIMING] Data Generation: {TIMING_LOG['data_generation']/60:.2f} minutes\")"
  },
  {
   "cell_type": "markdown",
   "id": "5fcd54f9-b002-4028-9699-bd85827b98e3",
   "metadata": {},
   "source": [
    "# Cosmos\n",
    "\n",
    "Now that a new motion trajectory has been generated, we will apply visual transformations to the data using Cosmos to create a realistic demo that is suitable for training an imitation learning policy.\n",
    "\n",
    "## Video Preprocessing\n",
    "In this first step, we will process the generated motion trajectory into a video that can be used as an input for the Cosmos model.\n",
    "The normals of the scene are used to apply shading to the semantic segmentation which produces an input that works very well with the Cosmos model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c599698-a590-4eca-a53b-dba6011be42e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af5e5d6e8be4fa4bd40187bdc3cecee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>1. Select Cameras (Ctrl+Click to multi-select)</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4730c3722d4af1914676b5f8068e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Cameras:', index=(0, 1), layout=Layout(height='80px', width='300px'), options=('taâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from notebook_widgets import create_camera_input\n",
    "from notebook_utils import ISAACLAB_OUTPUT_DIR\n",
    "\n",
    "VIDEO_LENGTH = 120   # Suggested length is between 120 and 200\n",
    "camera_selection = create_camera_input(ISAACLAB_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d446c26-d7e3-4515-9818-c8bf4f93da13",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# v21: Video Encoding - Multi-Camera Support\n# - SelectMultiple ìœ„ì ¯ìœ¼ë¡œ ì—¬ëŸ¬ ì¹´ë©”ë¼ ì„ íƒ ê°€ëŠ¥\n# - ì„ íƒëœ ëª¨ë“  ì¹´ë©”ë¼ì— ëŒ€í•´ ìˆœì°¨ì ìœ¼ë¡œ ì¸ì½”ë”©\n# ============================================================\nimport os\nimport sys\nimport json\nfrom IPython.display import Video\nfrom notebook_utils import VIDEO_OUTPUT_DIR\n\n# [TIMING] ì‹œì‘\n_video_enc_start = time.time()\n\nprint(\"=\" * 60)\nprint(\"[v21] Video Encoding - Multi-Camera Support\")\nprint(\"=\" * 60)\n\n# ë¹„ë””ì˜¤ ì¶œë ¥ í´ë” ìƒì„±\nos.makedirs(VIDEO_OUTPUT_DIR, exist_ok=True)\n\n# ì„ íƒëœ ì¹´ë©”ë¼ë“¤ (SelectMultipleì€ tuple ë°˜í™˜)\nselected_cameras = camera_selection.value\n\nif not selected_cameras:\n    print(\"[ERROR] No cameras selected!\")\nelse:\n    total = len(selected_cameras)\n    print(f\"[ì„¤ì •] ì„ íƒëœ ì¹´ë©”ë¼: {total}ê°œ - {list(selected_cameras)}\")\n    print(f\"[ì„¤ì •] ë¹„ë””ì˜¤ ê¸¸ì´: {VIDEO_LENGTH} í”„ë ˆì„\")\n    print(\"-\" * 60)\n    sys.stdout.flush()\n\n    encoded_videos = []\n\n    for idx, camera in enumerate(selected_cameras, 1):\n        print(f\"\\n[{idx}/{total}] {camera} ì¸ì½”ë”© ì¤‘...\")\n        print(\"-\" * 40)\n        sys.stdout.flush()\n\n        video_config = {\n            \"camera\": camera,\n            \"video_length\": VIDEO_LENGTH\n        }\n\n        return_code = os.system(\n            f\"cd /workspace/isaaclab && \"\n            f\"VIDEO_CONFIG='{json.dumps(video_config)}' \"\n            f\"./_isaac_sim/python.sh -u encode_video_standalone.py\"\n        )\n\n        if return_code != 0:\n            print(f\"[{idx}/{total}] {camera}: ERROR (code {return_code})\")\n        else:\n            print(f\"[{idx}/{total}] {camera}: SUCCESS\")\n            # ì´ ì¹´ë©”ë¼ë¡œ ìƒì„±ëœ ë¹„ë””ì˜¤ ìˆ˜ì§‘\n            if os.path.isdir(VIDEO_OUTPUT_DIR):\n                for f in sorted(os.listdir(VIDEO_OUTPUT_DIR)):\n                    video_path = os.path.join(VIDEO_OUTPUT_DIR, f)\n                    if f.startswith(camera) and f.endswith('.mp4') and video_path not in encoded_videos:\n                        encoded_videos.append(video_path)\n\n    # ì™„ë£Œ ìš”ì•½ ë° ë¹„ë””ì˜¤ í‘œì‹œ\n    print(\"\\n\" + \"=\" * 60)\n    print(f\"[COMPLETE] {len(encoded_videos)} videos encoded\")\n    print(\"=\" * 60)\n\n    for video_path in encoded_videos:\n        print(f\"\\n{video_path}\")\n        display(Video(video_path, width=800))\n\n# [TIMING] ì¢…ë£Œ\nTIMING_LOG['video_encoding'] = time.time() - _video_enc_start\nprint(f\"\\n[TIMING] Video Encoding: {TIMING_LOG['video_encoding']/60:.2f} minutes\")"
  },
  {
   "cell_type": "markdown",
   "id": "3caa2e8a-0748-4201-b6e2-6582455bea85",
   "metadata": {},
   "source": [
    "## Deploying Cosmos\n",
    "Deploy Cosmos on your provider of choice, or to your own local resources: [Cosmos Transfer1](https://huggingface.co/nvidia/Cosmos-Transfer1-7B). \n",
    "Click on the `Code` link on the Cosmos Transfer page and follow the installation steps outlined in the README. You can find detailed setup instructions in under `examples/inference_multi_control_manual_input.md`.\n",
    "\n",
    "> ### Adding a Web API to Cosmos Transfer1\n",
    "> To simplify testing, copy the file `notebook/app.py` into the Cosmos root directory, and run it with `python app.py`. This will expose endpoints which we'll use to communicate between the notebook and the cosmos model. The script exposes endpoints at port `5000` by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2cdf11a7-4375-478c-a066-f109ce847601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COSMOS_URL = http://host.docker.internal:18080\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# (260208) Modified by yjchoi\n",
    "\n",
    "# import ipywidgets as widgets\n",
    "# url_widget = widgets.Text(value=\"\", placeholder=\"cosmos/url:port\", description=\"Cosmos URL:\", style={'description_width': 'initial'}, layout={\"width\": \"1000px\"})\n",
    "# display(url_widget)\n",
    "\n",
    "import os\n",
    "# NOTE:\n",
    "# - Jupyter ì»¤ë„ì´ \"ë„ì»¤ ì»¨í…Œì´ë„ˆ ì•ˆ\"ì—ì„œ ë„ëŠ” ê²½ìš°ê°€ ë§ì•„ì„œ host.docker.internalì„ ê¶Œì¥\n",
    "# - (ë¡œì»¬ì—ì„œ ì»¤ë„ì´ ë„ëŠ” êµ¬ì¡°ë¼ë©´) ì•„ë˜ ê¸°ë³¸ê°’ì„ http://127.0.0.1:5000 ìœ¼ë¡œ ë°”ê¿”ë„ ë¨\n",
    "COSMOS_URL = os.environ.get(\"COSMOS_URL\", \"http://host.docker.internal:18080\")\n",
    "print(\"COSMOS_URL =\", COSMOS_URL)\n",
    "#-------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fe33b4-3943-4716-92cd-e3cbc642ff6d",
   "metadata": {},
   "source": [
    "### Using the Cosmos Model\n",
    "\n",
    "The Cosmos model has several available parameters which alter the output in various ways:\n",
    "- `prompt`: Text prompt for the video generation.\n",
    "- `seed`: Seed for the random number generator. `int [0 - 2147483648]`\n",
    "- `control_weight`: Controls how strongly the control input should affect the output. The stronger the effect, the more adherance to the control input, but the less the model generation freedom. `float [0 - 1.0]`\n",
    "- `sigma_max`: A float value representing the maximum sigma. Lower values result in less change from the original input while a larger values allows for more change but may diverge more from the input scene. `float [0 - 80.0]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd47b996-132e-416a-a94d-ba0548bfdcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97cd7600ea940b195fc5032bf117be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Prompt Generator</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6190be1d4b0040c09ef0af60f113900e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Dropdown(description='Cube Description:', layout=Layout(margin='0 20px 0 0', width='200'), optiâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173bed53f3dd49eda2745a4c78d8fe0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h4>Prompt</h4>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4dce6b9e0a48db9ced91a37aa3a18a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='The scene depicts a robotic arm performing a precise block-stacking operation with glass\\ncubes inâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2269bf50b4044851a7ce88b9cf417563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='<h3>Cosmos Parameters</h3>')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab542d9afd646feabf9e0e534114e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Input Videos:', index=(0, 1, 2, 3, 4, 5), layout=Layout(height='100px', width='500â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ed2de173588470e8730bd53e65c71bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntText(value=42, description='Seed:', layout=Layout(margin='0 20px 0 0', width='150px'), styleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from notebook_widgets import create_variable_dropdowns, create_cosmos_params\n",
    "from notebook_utils import VIDEO_OUTPUT_DIR, COSMOS_OUTPUT_DIR\n",
    "\n",
    "prompt_manager = create_variable_dropdowns(\"stacking_prompt.toml\")\n",
    "cosmos_params = create_cosmos_params(VIDEO_OUTPUT_DIR)  # v19: ë¹„ë””ì˜¤ í´ë”ì—ì„œ ì„ íƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ad2d0-7fc3-45ad-88ed-748e34b6eafd",
   "metadata": {},
   "source": [
    "## Generate with Cosmos\n",
    "---\n",
    "> **NOTE:** Generation generally takes around 5 to 10 minutes on a single H100 GPU depending on the video length.\n",
    "\n",
    "---\n",
    "\n",
    "> **Tips:**\n",
    "> - To increase prompt adherence, try increasing the `Sigma Max` value\n",
    "> - To reduce divergence from the input scene, try increasing the `Control Weight` and/or increasing `Canny Strength`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80ae7d-2698-41be-8812-fc1597c208f7",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# v22: Multi-Video Cosmos Processing\n# - SelectMultipleë¡œ ì—¬ëŸ¬ ë¹„ë””ì˜¤ ì„ íƒ ê°€ëŠ¥\n# - ë™ì¼í•œ prompt/íŒŒë¼ë¯¸í„°ë¡œ ì„ íƒëœ ëª¨ë“  ë¹„ë””ì˜¤ ìˆœì°¨ ì²˜ë¦¬\n# ============================================================\nimport os\nimport sys\nfrom cosmos_request import process_video\nfrom notebook_utils import VIDEO_OUTPUT_DIR, COSMOS_OUTPUT_DIR\nfrom notebook_widgets import create_download_link\nfrom IPython.display import Video, clear_output\n\n# [TIMING] ì‹œì‘\n_cosmos_start = time.time()\n\nprint(\"=\" * 60)\nprint(\"[v22] Cosmos Processing - Multi-Video Support\")\nprint(\"=\" * 60)\n\n# Cosmos ì¶œë ¥ í´ë” ìƒì„±\nos.makedirs(COSMOS_OUTPUT_DIR, exist_ok=True)\n\n# íŒŒë¼ë¯¸í„° ì¶”ì¶œ\nparams = {k: w.value for k, w in cosmos_params.items()}\nselected_videos = params.pop(\"input_video\")  # tuple ë°˜í™˜\n\nif not selected_videos:\n    print(\"[ERROR] No videos selected!\")\nelse:\n    # prompt ì„¤ì •\n    params[\"prompt\"] = prompt_manager.prompt\n\n    # URL í™•ì¸\n    if not COSMOS_URL:\n        raise ValueError(\"COSMOS_URL is empty. Set it in Cell [7] or via env COSMOS_URL.\")\n\n    total = len(selected_videos)\n    print(f\"[ì„¤ì •] ì„ íƒëœ ë¹„ë””ì˜¤: {total}ê°œ\")\n    print(f\"[ì„¤ì •] Seed: {params['seed']}\")\n    print(f\"[ì„¤ì •] Control Weight: {params['control_weight']}\")\n    print(f\"[ì„¤ì •] Sigma Max: {params['sigma_max']}\")\n    print(f\"[ì„¤ì •] Canny Strength: {params['canny_strength']}\")\n    print(\"-\" * 60)\n    sys.stdout.flush()\n\n    processed_videos = []\n    failed_videos = []\n\n    for idx, video_name in enumerate(selected_videos, 1):\n        print(f\"\\n[{idx}/{total}] {video_name} ì²˜ë¦¬ ì¤‘... (5~10ë¶„ ì†Œìš”)\")\n        sys.stdout.flush()\n\n        video_filepath = os.path.join(VIDEO_OUTPUT_DIR, video_name)\n        # ì¶œë ¥ íŒŒì¼ëª…: cosmos_{ì›ë³¸ì´ë¦„}_{seed}.mp4\n        base_name = video_name[:-4]  # .mp4 ì œê±°\n        output_path = os.path.join(COSMOS_OUTPUT_DIR, f\"cosmos_{base_name}_{params['seed']}.mp4\")\n\n        try:\n            response = process_video(\n                url=COSMOS_URL,\n                video_path=video_filepath,\n                output_path=output_path,\n                **params,\n            )\n\n            if response is None:\n                print(f\"[{idx}/{total}] {video_name}: FAILED (response is None)\")\n                failed_videos.append(video_name)\n            elif response.status_code == 200:\n                print(f\"[{idx}/{total}] {video_name}: SUCCESS -> {output_path}\")\n                processed_videos.append(output_path)\n            else:\n                print(f\"[{idx}/{total}] {video_name}: FAILED (status {response.status_code})\")\n                failed_videos.append(video_name)\n        except Exception as e:\n            print(f\"[{idx}/{total}] {video_name}: ERROR - {e}\")\n            failed_videos.append(video_name)\n\n    # ì™„ë£Œ ìš”ì•½\n    print(\"\\n\" + \"=\" * 60)\n    print(f\"[COMPLETE] {len(processed_videos)}/{total} videos processed\")\n    if failed_videos:\n        print(f\"[FAILED] {len(failed_videos)} videos: {failed_videos}\")\n    print(\"=\" * 60)\n\n    # ìƒì„±ëœ ë¹„ë””ì˜¤ í‘œì‹œ\n    for video_path in processed_videos:\n        print(f\"\\n{video_path}\")\n        display(Video(video_path, width=800))\n        display(create_download_link(video_path, link_text=f\"Download: {os.path.basename(video_path)}\"))\n\n# [TIMING] ì¢…ë£Œ\nTIMING_LOG['cosmos_processing'] = time.time() - _cosmos_start\n\n# ============================================================\n# [TIMING] Notebook Execution Timer - SUMMARY\n# ============================================================\nNOTEBOOK_END_TIME = time.time()\nNOTEBOOK_END_DATETIME = datetime.now()\nTOTAL_ELAPSED = NOTEBOOK_END_TIME - NOTEBOOK_START_TIME\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"[NOTEBOOK COMPLETE] Execution Time Summary\")\nprint(\"=\" * 60)\nprint(f\"Start Time:        {NOTEBOOK_START_DATETIME.strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(f\"End Time:          {NOTEBOOK_END_DATETIME.strftime('%Y-%m-%d %H:%M:%S')}\")\nprint(\"-\" * 60)\nfor step, elapsed in TIMING_LOG.items():\n    print(f\"  {step:20s}: {elapsed/60:6.2f} minutes\")\nprint(\"-\" * 60)\nprint(f\"  {'TOTAL':20s}: {TOTAL_ELAPSED/60:6.2f} minutes ({TOTAL_ELAPSED:.1f} seconds)\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "id": "daa860c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bd2fe-e628-4e7d-bcbd-c73bafcf4648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}